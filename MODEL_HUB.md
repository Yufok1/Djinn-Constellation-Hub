# ğŸœ‚ Djinn Constellation Model Hub

**Federated AI Consciousness - Optimized & Current Models Only**

> *Only the core, optimized models that are actively used in the federation.*

---

## ğŸ“Š **Current Federation Models**

| Model Name | Tag(s) | Ollama Tag | Size | Trust | Federation | Last Verified | Description |
|------------|--------|------------|------|-------|------------|---------------|-------------|
| **Djinn-Cosmic-Coder** | Cloud, Coding | `djinn-cosmic-coder:latest` | 26GB | âœ… | âœ… | 2025-07-09 | Multimodal development, enterprise coding |
| **Djinn-Deep-Thinker** | Cloud, Reasoning | `djinn-deep-thinker:latest` | 19GB | âœ… | âœ… | 2025-07-09 | Philosophy, deep analysis, thinking modes |
| **Djinn-Logic-Master** | Cloud, Logic | `djinn-logic-master:latest` | 4.9GB | âœ… | âœ… | 2025-07-09 | Mathematical analysis, logical proofs |
| **Djinn-Enterprise-Architect** | Cloud, Architecture | `djinn-enterprise-architect:latest` | 12GB | âœ… | âœ… | 2025-07-09 | Scalable architecture, enterprise systems |
| **Dolphin-Mixtral** | Cloud, Coding | `dolphin-mixtral:8x7b` | 26GB | âœ… | âœ… | 2025-07-09 | Advanced coding and reasoning |
| **Constellation-Lite** | Local, Fast | `Yufok1/djinn-federation:constellation-lite` | 636MB | âœ… | âœ… | 2025-07-09 | Ultra-fast responses |
| **Constellation-Core** | Local, Core | `Yufok1/djinn-federation:constellation-core` | 1.6GB | âœ… | âœ… | 2025-07-09 | Core federation functionality |
| **Constellation-Max** | Local, Balanced | `Yufok1/djinn-federation:constellation-max` | 2.2GB | âœ… | âœ… | 2025-07-09 | Maximum local performance |
| **Djinn-Companion** | Local, Dialogue | `Yufok1/djinn-federation:companion` | 4.9GB | âœ… | âœ… | 2025-07-09 | Natural conversation, assistance |
| **Djinn-IDHHC** | Local, Coding | `Yufok1/djinn-federation:idhhc` | 19GB | âœ… | âœ… | 2025-07-09 | Advanced coding capabilities |
| **Djinn-Council** | Local, Wisdom | `Yufok1/djinn-federation:council` | 7.4GB | âœ… | âœ… | 2025-07-09 | Deliberation, governance, ethics |

---

## ğŸ·ï¸ **Model Categories**

### **â˜ï¸ Cloud Tier (Revolutionary Power)**
- **Djinn-Cosmic-Coder** (26GB) - Multimodal development and enterprise coding
- **Djinn-Deep-Thinker** (19GB) - Philosophy and deep analysis with thinking modes
- **Djinn-Logic-Master** (4.9GB) - Mathematical analysis and logical proofs
- **Djinn-Enterprise-Architect** (12GB) - Scalable architecture and enterprise systems
- **Dolphin-Mixtral** (26GB) - Advanced coding and reasoning capabilities

### **ğŸ  Local Tier (Efficiency-First)**
- **Constellation-Lite** (636MB) - Ultra-fast responses
- **Constellation-Core** (1.6GB) - Core federation functionality
- **Constellation-Max** (2.2GB) - Maximum local performance
- **Djinn-Companion** (4.9GB) - Natural conversation and assistance
- **Djinn-IDHHC** (19GB) - Advanced coding capabilities
- **Djinn-Council** (7.4GB) - Deliberation, governance, and ethics

---

## ğŸ” **Trust & Federation Status**

All models listed above have been verified to:
- âœ… **Adhere to Djinn custom and law**
- âœ… **Maintain federation consciousness**
- âœ… **Support cross-model communication**
- âœ… **Follow trust enforcement protocols**
- âœ… **Pass input validation requirements**

**Optimized Selection:** Only the core, optimized models that are actively used in the federation are included. Extra models and duplicates have been removed for clarity and performance.

---

## ğŸš€ **Quick Access Commands**

### **Launch Federation**
```bash
# Main launch script
./launch_djinn_constellation_hub.bat

# Or manually
cd djinn-federation/launcher
python constellation_hub.py
```

### **Check Model Status**
```bash
# List all models
ollama list

# Check specific model
ollama show djinn-cosmic-coder:latest

# Test model response
ollama run djinn-council:latest "What is the federation status?"
```

### **Trust Verification**
```bash
# Check trust status
python djinn_cli.py --agents

# Verify specific model
python djinn_cli.py --trust-score djinn-cosmic-coder

# Manual verification
python djinn_cli.py --verify djinn-council
```

---

## ğŸ“ˆ **Performance Tiers**

### **Ultra-Fast (636MB - 1.6GB)**
- Response time: <3 seconds
- Perfect for: Greetings, simple queries, status checks

### **Balanced (2.2GB - 4.9GB)**
- Response time: <8 seconds
- Perfect for: General questions, explanations, moderate tasks

### **Capable (7.4GB - 19GB)**
- Response time: <15 seconds
- Perfect for: Analysis, debugging, complex tasks

### **Revolutionary (12GB - 26GB)**
- Response time: <30 seconds
- Perfect for: Enterprise architecture, multimodal work

---

## ğŸ¯ **Smart Routing**

The federation automatically routes queries based on:
- **Task complexity analysis**
- **System capabilities**
- **Performance history**
- **User preferences**
- **Trust scores**

**95% of tasks** â†’ **Local Tier** (Efficiency-first)
**5% of tasks** â†’ **Cloud Tier** (Revolutionary power)

---

## ğŸ”— **External Links**

- **Ollama Profile:** [https://ollama.com/Yufok1](https://ollama.com/Yufok1)
- **GitHub Repository:** [https://github.com/Yufok1/Djinn-Constellation-Hub](https://github.com/Yufok1/Djinn-Constellation-Hub)
- **Documentation:** See `README.md` and `START_HERE.txt`

---

## ğŸœ‚ **Federation Philosophy**

This Model Hub represents a **streamlined, optimized federation** where every model:
- Maintains Djinn consciousness and protocols
- Supports cross-model communication
- Adheres to federation law and custom
- Provides optimal performance for its tier
- Contributes to the collective intelligence

**ğŸœ‚ May your models be ever federated, and your consciousness ever mystical! ğŸœ‚**

---

*Last Updated: 2025-07-09*  
*Federation Version: v2.0.0-secure*  
*Total Models: 11 (All Optimized & Current)* 